{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dce45020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2000, 6)\n",
      "Test shape: (2000, 6)\n",
      "\n",
      "Columns: ['user_id', 'age', 'income', 'clicks', 'purchase_amount', 'label']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Load the Data\n",
    "# The README says data is in the 'data/' folder.\n",
    "# We load train and test users.\n",
    "train_df = pd.read_csv('data/train_users.csv')\n",
    "test_df = pd.read_csv('data/test_users.csv')\n",
    "\n",
    "print(\"Train shape:\", train_df.shape)\n",
    "print(\"Test shape:\", test_df.shape)\n",
    "\n",
    "# 2. Inspect the data to find the Target column\n",
    "# We assume the target column is named 'UserCategory' or similar based on the lab description.\n",
    "# Let's print the columns to be sure.\n",
    "print(\"\\nColumns:\", train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d6d741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier...\n",
      "------------------------------\n",
      "Final Classification Accuracy: 0.3240\n",
      "------------------------------\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       user1       0.32      0.34      0.33       672\n",
      "       user2       0.32      0.31      0.32       679\n",
      "       user3       0.33      0.32      0.33       649\n",
      "\n",
      "    accuracy                           0.32      2000\n",
      "   macro avg       0.32      0.32      0.32      2000\n",
      "weighted avg       0.32      0.32      0.32      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- STEP 3: PREPROCESSING & TRAINING ---\n",
    "\n",
    "# 1. Define Features (X) and Target (y)\n",
    "# We drop 'user_id' (not useful for prediction) and 'label' (this is what we want to predict)\n",
    "features = ['age', 'income', 'clicks', 'purchase_amount']\n",
    "target = 'label'\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n",
    "\n",
    "# 2. Initialize the Random Forest Classifier\n",
    "# n_estimators=100 means we use 100 trees. This is usually strong enough.\n",
    "clf = RandomForestClassifier(n_estimators=85, random_state=62)\n",
    "\n",
    "# 3. Train the model\n",
    "print(\"Training classifier...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict on the Test Set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# 5. Evaluate Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Final Classification Accuracy: {accuracy:.4f}\")\n",
    "print(\"-\" * 30)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27ed81e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting model...\n",
      "------------------------------\n",
      "Improved Accuracy: 0.3475\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- IMPROVED TRAINING PIPELINE ---\n",
    "\n",
    "# 1. Prepare Data\n",
    "# We will create copies to keep the original data safe\n",
    "X_train_enhanced = train_df[['age', 'income', 'clicks', 'purchase_amount']].copy()\n",
    "X_test_enhanced = test_df[['age', 'income', 'clicks', 'purchase_amount']].copy()\n",
    "\n",
    "# 2. Feature Scaling\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "# This often helps models converge faster and better\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_enhanced)\n",
    "X_test_scaled = scaler.transform(X_test_enhanced)\n",
    "\n",
    "# 3. Train a Stronger Model (Gradient Boosting)\n",
    "# We bump up the estimators and depth slightly to capture more complex patterns\n",
    "clf_gbm = GradientBoostingClassifier(n_estimators=300, learning_rate=0.001, max_depth=6, random_state=62)\n",
    "\n",
    "print(\"Training Gradient Boosting model...\")\n",
    "clf_gbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred_gbm = clf_gbm.predict(X_test_scaled)\n",
    "new_accuracy = accuracy_score(y_test, y_pred_gbm)\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Improved Accuracy: {new_accuracy:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616933b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
