{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999bcd7d",
   "metadata": {},
   "source": [
    "# Lab 3: Contextual Bandit-Based News Article Recommendation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755efd7a",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef4bd959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports loaded and sampler initialized (roll_number=83)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from rlcmab_sampler import sampler\n",
    "\n",
    "# Initialize the reward sampler with roll number\n",
    "# U20230083 → i = 83\n",
    "reward_sampler = sampler(83)\n",
    "\n",
    "print(\"✓ All imports loaded and sampler initialized (roll_number=83)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c638ba06",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48f6f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== News Articles ===\n",
      "Shape: (209527, 6)\n",
      "Columns: ['link', 'headline', 'category', 'short_description', 'authors', 'date']\n",
      "All categories: ['ARTS', 'ARTS & CULTURE', 'BLACK VOICES', 'BUSINESS', 'COLLEGE', 'COMEDY', 'CRIME', 'CULTURE & ARTS', 'DIVORCE', 'EDUCATION', 'ENTERTAINMENT', 'ENVIRONMENT', 'FIFTY', 'FOOD & DRINK', 'GOOD NEWS', 'GREEN', 'HEALTHY LIVING', 'HOME & LIVING', 'IMPACT', 'LATINO VOICES', 'MEDIA', 'MONEY', 'PARENTING', 'PARENTS', 'POLITICS', 'QUEER VOICES', 'RELIGION', 'SCIENCE', 'SPORTS', 'STYLE', 'STYLE & BEAUTY', 'TASTE', 'TECH', 'THE WORLDPOST', 'TRAVEL', 'U.S. NEWS', 'WEDDINGS', 'WEIRD NEWS', 'WELLNESS', 'WOMEN', 'WORLD NEWS', 'WORLDPOST']\n",
      "\n",
      "=== Train Users ===\n",
      "Shape: (2000, 33)\n",
      "Label distribution:\n",
      "label\n",
      "user_2    712\n",
      "user_1    707\n",
      "user_3    581\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Test Users ===\n",
      "Shape: (2000, 32)\n",
      "Has 'label' column: False\n"
     ]
    }
   ],
   "source": [
    "# Load all three datasets\n",
    "news_df = pd.read_csv(\"data/news_articles.csv\")\n",
    "train_users = pd.read_csv(\"data/train_users.csv\")\n",
    "test_users = pd.read_csv(\"data/test_users.csv\")\n",
    "\n",
    "print(\"=== News Articles ===\")\n",
    "print(f\"Shape: {news_df.shape}\")\n",
    "print(f\"Columns: {list(news_df.columns)}\")\n",
    "print(f\"All categories: {sorted(news_df['category'].unique())}\")\n",
    "print()\n",
    "\n",
    "print(\"=== Train Users ===\")\n",
    "print(f\"Shape: {train_users.shape}\")\n",
    "print(f\"Label distribution:\\n{train_users['label'].value_counts()}\")\n",
    "print()\n",
    "\n",
    "print(\"=== Test Users ===\")\n",
    "print(f\"Shape: {test_users.shape}\")\n",
    "print(f\"Has 'label' column: {'label' in test_users.columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c5cb1",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section:\n",
    "- Handle missing values\n",
    "- Encode categorical features\n",
    "- Prepare data for user classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71e7bf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "  train_users: 2000 rows, NaN count: 698\n",
      "  test_users:  2000 rows, NaN count: 679\n",
      "  news_df:     209527 rows, NaN count: 57136\n",
      "\n",
      "After dropping NaN rows:\n",
      "  train_users: 1302 rows\n",
      "  test_users:  1321 rows\n",
      "  news_df:     156859 rows\n",
      "\n",
      "User category encoding: {'user_1': np.int64(0), 'user_2': np.int64(1), 'user_3': np.int64(2)}\n",
      "\n",
      "News category mapping (per Table 1): {'ENTERTAINMENT': 0, 'EDUCATION': 1, 'TECH': 2, 'CRIME': 3}\n",
      "Filtered news articles: 18130 (from 156859 total)\n",
      "Articles per category:\n",
      "category\n",
      "ENTERTAINMENT    13463\n",
      "CRIME             2093\n",
      "TECH              1681\n",
      "EDUCATION          893\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ Preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "# --- Data Cleaning ---\n",
    "print(f\"Before cleaning:\")\n",
    "print(f\"  train_users: {train_users.shape[0]} rows, NaN count: {train_users.isna().sum().sum()}\")\n",
    "print(f\"  test_users:  {test_users.shape[0]} rows, NaN count: {test_users.isna().sum().sum()}\")\n",
    "print(f\"  news_df:     {news_df.shape[0]} rows, NaN count: {news_df.isna().sum().sum()}\")\n",
    "\n",
    "train_users_clean = train_users.dropna().copy()\n",
    "test_users_clean = test_users.dropna().copy()\n",
    "news_df_clean = news_df.dropna().copy()\n",
    "\n",
    "print(f\"\\nAfter dropping NaN rows:\")\n",
    "print(f\"  train_users: {train_users_clean.shape[0]} rows\")\n",
    "print(f\"  test_users:  {test_users_clean.shape[0]} rows\")\n",
    "print(f\"  news_df:     {news_df_clean.shape[0]} rows\")\n",
    "\n",
    "# --- Encode User Categories ---\n",
    "# The 'label' column in train_users contains: user_1, user_2, user_3\n",
    "user_encoder = LabelEncoder()\n",
    "train_users_clean['user_category_encoded'] = user_encoder.fit_transform(train_users_clean['label'])\n",
    "\n",
    "print(f\"\\nUser category encoding: {dict(zip(user_encoder.classes_, user_encoder.transform(user_encoder.classes_)))}\")\n",
    "\n",
    "# --- Filter and Encode News Categories ---\n",
    "# Assignment specifies 4 categories: Entertainment, Education, Tech, Crime\n",
    "target_categories = ['ENTERTAINMENT', 'EDUCATION', 'TECH', 'CRIME']\n",
    "news_df_filtered = news_df_clean[news_df_clean['category'].isin(target_categories)].copy()\n",
    "\n",
    "# Encode according to Table 1 mapping:\n",
    "# j=0 → Entertainment, j=1 → Education, j=2 → Tech, j=3 → Crime\n",
    "news_category_mapping = {\n",
    "    'ENTERTAINMENT': 0,\n",
    "    'EDUCATION': 1,\n",
    "    'TECH': 2,\n",
    "    'CRIME': 3\n",
    "}\n",
    "news_df_filtered['category_encoded'] = news_df_filtered['category'].map(news_category_mapping)\n",
    "\n",
    "idx_to_news_name = {v: k for k, v in news_category_mapping.items()}\n",
    "user_to_idx = {cat: idx for idx, cat in enumerate(user_encoder.classes_)}\n",
    "\n",
    "print(f\"\\nNews category mapping (per Table 1): {news_category_mapping}\")\n",
    "print(f\"Filtered news articles: {news_df_filtered.shape[0]} (from {news_df_clean.shape[0]} total)\")\n",
    "print(f\"Articles per category:\\n{news_df_filtered['category'].value_counts()}\")\n",
    "print(\"\\n✓ Preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d6352",
   "metadata": {},
   "source": [
    "## User Classification\n",
    "\n",
    "Train a classifier to predict the user category (`User1`, `User2`, `User3`),\n",
    "which serves as the **context** for the contextual bandit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dadc1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping columns: ['user_id', 'browser_version', 'region_code', 'subscriber', 'label', 'user_category_encoded']\n",
      "Feature columns (28): ['age', 'income', 'clicks', 'purchase_amount', 'session_duration', 'content_variety', 'engagement_score', 'num_transactions', 'avg_monthly_spend', 'avg_cart_value', 'browsing_depth', 'revisit_rate', 'scroll_activity', 'time_on_site', 'interaction_count', 'preferred_price_range', 'discount_usage_rate', 'wishlist_size', 'product_views', 'repeat_purchase_gap (days)', 'churn_risk_score', 'loyalty_index', 'screen_brightness', 'battery_percentage', 'cart_abandonment_count', 'background_app_count', 'session_inactivity_duration', 'network_jitter']\n",
      "\n",
      "Training set: 1041 samples\n",
      "Validation set: 261 samples\n",
      "\n",
      "==================================================\n",
      "Validation Accuracy: 0.8889\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      user_1       0.85      0.96      0.90       113\n",
      "      user_2       0.96      0.94      0.95       126\n",
      "      user_3       0.50      0.23      0.31        22\n",
      "\n",
      "    accuracy                           0.89       261\n",
      "   macro avg       0.77      0.71      0.72       261\n",
      "weighted avg       0.87      0.89      0.88       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare features for classification ---\n",
    "# Identify non-numeric columns to exclude\n",
    "non_numeric_cols = train_users_clean.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "# Also exclude the encoded target\n",
    "cols_to_drop = non_numeric_cols + ['user_category_encoded']\n",
    "print(f\"Dropping columns: {cols_to_drop}\")\n",
    "\n",
    "X = train_users_clean.drop(columns=cols_to_drop)\n",
    "y = train_users_clean['user_category_encoded']\n",
    "\n",
    "feature_columns = X.columns.tolist()\n",
    "print(f\"Feature columns ({len(feature_columns)}): {feature_columns}\")\n",
    "\n",
    "# 80/20 train/validation split (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_val_pred = clf.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, target_names=user_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU Env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
