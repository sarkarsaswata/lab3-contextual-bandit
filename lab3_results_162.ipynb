{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999bcd7d",
   "metadata": {},
   "source": [
    "# Lab 3: Contextual Bandit-Based News Article Recommendation\n",
    "\n",
    "**`Course`:** Reinforcement Learning Fundamentals  \n",
    "**`Student Name`:** Sohan  \n",
    "**`Roll Number`:** U20230162  \n",
    "**`GitHub Branch`:** sohan_U20230162  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755efd7a",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef4bd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from rlcmab_sampler import sampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c638ba06",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f6f6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET OVERVIEW ===\n",
      "\n",
      "News Articles: 209527 articles, 6 features\n",
      "Train Users: 2000 users, 33 features\n",
      "Test Users: 2000 users, 32 features\n",
      "\n",
      "=== News Categories ===\n",
      "category\n",
      "POLITICS          35602\n",
      "WELLNESS          17945\n",
      "ENTERTAINMENT     17362\n",
      "TRAVEL             9900\n",
      "STYLE & BEAUTY     9814\n",
      "PARENTING          8791\n",
      "HEALTHY LIVING     6694\n",
      "QUEER VOICES       6347\n",
      "FOOD & DRINK       6340\n",
      "BUSINESS           5992\n",
      "COMEDY             5400\n",
      "SPORTS             5077\n",
      "BLACK VOICES       4583\n",
      "HOME & LIVING      4320\n",
      "PARENTS            3955\n",
      "THE WORLDPOST      3664\n",
      "WEDDINGS           3653\n",
      "WOMEN              3572\n",
      "CRIME              3562\n",
      "IMPACT             3484\n",
      "DIVORCE            3426\n",
      "WORLD NEWS         3299\n",
      "MEDIA              2944\n",
      "WEIRD NEWS         2777\n",
      "GREEN              2622\n",
      "WORLDPOST          2579\n",
      "RELIGION           2577\n",
      "STYLE              2254\n",
      "SCIENCE            2206\n",
      "TECH               2104\n",
      "TASTE              2096\n",
      "MONEY              1756\n",
      "ARTS               1509\n",
      "ENVIRONMENT        1444\n",
      "FIFTY              1401\n",
      "GOOD NEWS          1398\n",
      "U.S. NEWS          1377\n",
      "ARTS & CULTURE     1339\n",
      "COLLEGE            1144\n",
      "LATINO VOICES      1130\n",
      "CULTURE & ARTS     1074\n",
      "EDUCATION          1014\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== User Labels ===\n",
      "label\n",
      "user_2    712\n",
      "user_1    707\n",
      "user_3    581\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load datasets\n",
    "news_df = pd.read_csv(\"data/news_articles.csv\")\n",
    "train_users = pd.read_csv(\"data/train_users.csv\")\n",
    "test_users = pd.read_csv(\"data/test_users.csv\")\n",
    "\n",
    "print(\"=== DATASET OVERVIEW ===\")\n",
    "print(f\"\\nNews Articles: {news_df.shape[0]} articles, {news_df.shape[1]} features\")\n",
    "print(f\"Train Users: {train_users.shape[0]} users, {train_users.shape[1]} features\")\n",
    "print(f\"Test Users: {test_users.shape[0]} users, {test_users.shape[1]} features\")\n",
    "\n",
    "print(\"\\n=== News Categories ===\")\n",
    "print(news_df['category'].value_counts())\n",
    "\n",
    "print(\"\\n=== User Labels ===\")\n",
    "print(train_users['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c5cb1",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section:\n",
    "- Handle missing values\n",
    "- Encode categorical features\n",
    "- Prepare data for user classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74091bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA PREPROCESSING ===\n",
      "\n",
      "Missing values in train_users:\n",
      "user_id                          0\n",
      "age                            698\n",
      "income                           0\n",
      "clicks                           0\n",
      "purchase_amount                  0\n",
      "session_duration                 0\n",
      "content_variety                  0\n",
      "engagement_score                 0\n",
      "num_transactions                 0\n",
      "avg_monthly_spend                0\n",
      "avg_cart_value                   0\n",
      "browsing_depth                   0\n",
      "revisit_rate                     0\n",
      "scroll_activity                  0\n",
      "time_on_site                     0\n",
      "interaction_count                0\n",
      "preferred_price_range            0\n",
      "discount_usage_rate              0\n",
      "wishlist_size                    0\n",
      "product_views                    0\n",
      "repeat_purchase_gap (days)       0\n",
      "churn_risk_score                 0\n",
      "loyalty_index                    0\n",
      "screen_brightness                0\n",
      "battery_percentage               0\n",
      "cart_abandonment_count           0\n",
      "browser_version                  0\n",
      "background_app_count             0\n",
      "session_inactivity_duration      0\n",
      "network_jitter                   0\n",
      "region_code                      0\n",
      "subscriber                       0\n",
      "label                            0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in test_users:\n",
      "user_id                          0\n",
      "age                            679\n",
      "income                           0\n",
      "clicks                           0\n",
      "purchase_amount                  0\n",
      "session_duration                 0\n",
      "content_variety                  0\n",
      "engagement_score                 0\n",
      "num_transactions                 0\n",
      "avg_monthly_spend                0\n",
      "avg_cart_value                   0\n",
      "browsing_depth                   0\n",
      "revisit_rate                     0\n",
      "scroll_activity                  0\n",
      "time_on_site                     0\n",
      "interaction_count                0\n",
      "preferred_price_range            0\n",
      "discount_usage_rate              0\n",
      "wishlist_size                    0\n",
      "product_views                    0\n",
      "repeat_purchase_gap (days)       0\n",
      "churn_risk_score                 0\n",
      "loyalty_index                    0\n",
      "screen_brightness                0\n",
      "battery_percentage               0\n",
      "cart_abandonment_count           0\n",
      "browser_version                  0\n",
      "background_app_count             0\n",
      "session_inactivity_duration      0\n",
      "network_jitter                   0\n",
      "region_code                      0\n",
      "subscriber                       0\n",
      "dtype: int64\n",
      "\n",
      "Label Mapping: {0: 'user_1', 1: 'user_2', 2: 'user_3'}\n",
      "\n",
      "Preprocessed data shapes:\n",
      "X_train: (2000, 32)\n",
      "X_test: (2000, 32)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "print(\"=== DATA PREPROCESSING ===\")\n",
    "\n",
    "# Handle missing values in train_users\n",
    "print(f\"\\nMissing values in train_users:\\n{train_users.isnull().sum()}\")\n",
    "train_users_clean = train_users.dropna(subset=['label'])  # Remove rows with missing labels\n",
    "train_users_clean = train_users_clean.fillna(train_users_clean.mean(numeric_only=True))\n",
    "\n",
    "print(f\"\\nMissing values in test_users:\\n{test_users.isnull().sum()}\")\n",
    "test_users_clean = test_users.fillna(test_users.mean(numeric_only=True))\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_users_clean.drop('label', axis=1)\n",
    "y_train = train_users_clean['label']\n",
    "\n",
    "# Encode categorical features\n",
    "le_dict = {}\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "    le_dict[col] = le\n",
    "\n",
    "# Apply same encoding to test_users - handle unknown values\n",
    "X_test = test_users_clean.copy()\n",
    "for col in categorical_cols:\n",
    "    if col in le_dict:\n",
    "        # Handle unknown values by assigning them a default value (0)\n",
    "        X_test[col] = X_test[col].astype(str)\n",
    "        known_values = set(le_dict[col].classes_)\n",
    "        X_test[col] = X_test[col].apply(\n",
    "            lambda x: le_dict[col].transform([x])[0] if x in known_values else 0\n",
    "        )\n",
    "\n",
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "label_map = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "print(f\"\\nLabel Mapping: {label_map}\")\n",
    "print(f\"\\nPreprocessed data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d6352",
   "metadata": {},
   "source": [
    "## User Classification\n",
    "\n",
    "Train a classifier to predict the user category (`User1`, `User2`, `User3`),\n",
    "which serves as the **context** for the contextual bandit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8613bd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== USER CLASSIFICATION MODEL ===\n",
      "Training set size: 1600 (80%)\n",
      "Validation set size: 400 (20%)\n",
      "\n",
      "Validation Accuracy: 0.9000\n",
      "\n",
      "=== Classification Report (Validation Set) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      user_1       0.89      0.86      0.87       142\n",
      "      user_2       0.97      0.89      0.93       142\n",
      "      user_3       0.84      0.97      0.90       116\n",
      "\n",
      "    accuracy                           0.90       400\n",
      "   macro avg       0.90      0.90      0.90       400\n",
      "weighted avg       0.90      0.90      0.90       400\n",
      "\n",
      "\n",
      "Test Set Predictions:\n",
      "User1: 720\n",
      "User2: 760\n",
      "User3: 520\n"
     ]
    }
   ],
   "source": [
    "# Split data for user classification\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train, y_train_encoded, test_size=0.2, random_state=42, stratify=y_train_encoded\n",
    ")\n",
    "\n",
    "print(\"=== USER CLASSIFICATION MODEL ===\")\n",
    "print(f\"Training set size: {X_train_split.shape[0]} ({80}%)\")\n",
    "print(f\"Validation set size: {X_val_split.shape[0]} ({20}%)\")\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "user_classifier = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
    "user_classifier.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Evaluate on validation set\n",
    "y_pred_val = user_classifier.predict(X_val_split)\n",
    "val_accuracy = accuracy_score(y_val_split, y_pred_val)\n",
    "\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy:.4f}\")\n",
    "print(\"\\n=== Classification Report (Validation Set) ===\")\n",
    "print(classification_report(y_val_split, y_pred_val, target_names=label_encoder.classes_))\n",
    "\n",
    "# Predict on test set\n",
    "test_user_predictions = user_classifier.predict(X_test)\n",
    "test_user_contexts = np.array([label_encoder.classes_[pred] for pred in test_user_predictions])\n",
    "\n",
    "print(f\"\\nTest Set Predictions:\")\n",
    "print(f\"User1: {np.sum(test_user_predictions == 0)}\")\n",
    "print(f\"User2: {np.sum(test_user_predictions == 1)}\")\n",
    "print(f\"User3: {np.sum(test_user_predictions == 2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
