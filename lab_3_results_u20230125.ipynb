{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67281f08",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "YOUR_ROLL_NUMBER = 125\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LAB 3: CONTEXTUAL BANDIT-BASED NEWS RECOMMENDATION SYSTEM\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Roll Number: {YOUR_ROLL_NUMBER}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 1: DATA PRE-PROCESSING (10 POINTS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 1: DATA PRE-PROCESSING (10 POINTS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.1 Load Datasets\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[1.1] Loading Datasets...\")\n",
    "\n",
    "try:\n",
    "    news_articles = pd.read_csv('data/news_articles.csv', engine='python')\n",
    "    train_users = pd.read_csv('data/train_users.csv')\n",
    "    test_users = pd.read_csv('data/test_users.csv')\n",
    "\n",
    "    print(\"✓ All datasets loaded successfully!\")\n",
    "    print(f\"\\n  - News Articles shape: {news_articles.shape}\")\n",
    "    print(f\"  - Train Users shape: {train_users.shape}\")\n",
    "    print(f\"  - Test Users shape: {test_users.shape}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error: {e}\")\n",
    "    print(\"Please upload the CSV files to your Colab environment.\")\n",
    "    raise\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.2 Exploratory Data Analysis\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[1.2] Exploratory Data Analysis...\")\n",
    "\n",
    "print(\"\\n--- News Articles Dataset ---\")\n",
    "print(news_articles.head())\n",
    "print(f\"\\nColumns: {news_articles.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\\n{news_articles.dtypes}\")\n",
    "print(f\"\\nNews Categories Distribution:\\n{news_articles['category'].value_counts()}\")\n",
    "\n",
    "print(\"\\n--- Train Users Dataset ---\")\n",
    "print(train_users.head())\n",
    "print(f\"\\nColumns: {train_users.columns.tolist()}\")\n",
    "print(f\"\\nData Types:\\n{train_users.dtypes}\")\n",
    "\n",
    "# Find the label column (should contain User1, User2, User3)\n",
    "user_label_col = None\n",
    "for col in train_users.columns:\n",
    "    if train_users[col].dtype == 'object':\n",
    "        unique_vals = train_users[col].unique()\n",
    "        if any('User' in str(val) for val in unique_vals):\n",
    "            user_label_col = col\n",
    "            break\n",
    "\n",
    "if user_label_col is None:\n",
    "    # Try last column\n",
    "    user_label_col = train_users.columns[-1]\n",
    "\n",
    "print(f\"\\nUser Label Column: '{user_label_col}'\")\n",
    "print(f\"User Categories Distribution:\\n{train_users[user_label_col].value_counts()}\")\n",
    "\n",
    "print(\"\\n--- Test Users Dataset ---\")\n",
    "print(test_users.head())\n",
    "print(f\"\\nColumns: {test_users.columns.tolist()}\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.3 Data Cleaning - Handle Missing Values\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[1.3] Handling Missing Values...\")\n",
    "\n",
    "def check_missing_values(df, dataset_name):\n",
    "    \"\"\"Check and display missing values\"\"\"\n",
    "    missing = df.isnull().sum()\n",
    "    if missing.sum() > 0:\n",
    "        print(f\"\\nMissing values in {dataset_name}:\")\n",
    "        print(missing[missing > 0])\n",
    "    else:\n",
    "        print(f\"\\n✓ No missing values in {dataset_name}\")\n",
    "    return missing\n",
    "\n",
    "# Check missing values\n",
    "check_missing_values(news_articles, \"News Articles\")\n",
    "check_missing_values(train_users, \"Train Users\")\n",
    "check_missing_values(test_users, \"Test Users\")\n",
    "\n",
    "def handle_missing_values(df, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Handle missing values in the dataframe\n",
    "    - Numerical columns: fill with median\n",
    "    - Categorical columns: fill with mode\n",
    "    \"\"\"\n",
    "    df_clean = df.copy()\n",
    "    missing_handled = False\n",
    "\n",
    "    # Numerical columns\n",
    "    num_cols = df_clean.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            df_clean[col].fillna(df_clean[col].median(), inplace=True)\n",
    "            print(f\"  {dataset_name}: Filled '{col}' with median\")\n",
    "            missing_handled = True\n",
    "\n",
    "    # Categorical columns\n",
    "    cat_cols = df_clean.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        if df_clean[col].isnull().sum() > 0:\n",
    "            mode_val = df_clean[col].mode()\n",
    "            fill_val = mode_val[0] if len(mode_val) > 0 else 'Unknown'\n",
    "            df_clean[col].fillna(fill_val, inplace=True)\n",
    "            print(f\"  {dataset_name}: Filled '{col}' with mode\")\n",
    "            missing_handled = True\n",
    "\n",
    "    if not missing_handled:\n",
    "        print(f\"  {dataset_name}: No missing values to handle\")\n",
    "\n",
    "    return df_clean\n",
    "\n",
    "# Clean all datasets\n",
    "news_articles_clean = handle_missing_values(news_articles, \"News Articles\")\n",
    "train_users_clean = handle_missing_values(train_users, \"Train Users\")\n",
    "test_users_clean = handle_missing_values(test_users, \"Test Users\")\n",
    "\n",
    "print(\"\\n✓ Missing values handled successfully!\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1.4 Feature Encoding\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[1.4] Feature Encoding...\")\n",
    "\n",
    "# Separate features and labels for user datasets\n",
    "X_train = train_users_clean.drop(columns=[user_label_col])\n",
    "y_train = train_users_clean[user_label_col]\n",
    "\n",
    "# Check if user_label_col exists in test_users_clean for proper separation and evaluation\n",
    "if user_label_col in test_users_clean.columns:\n",
    "    X_test = test_users_clean.drop(columns=[user_label_col])\n",
    "    y_test = test_users_clean[user_label_col]\n",
    "    test_labels_available = True\n",
    "else:\n",
    "    # If test_users_clean does not have the label column, treat all columns as features\n",
    "    X_test = test_users_clean.copy()\n",
    "    # Create a dummy series for y_test to avoid KeyErrors downstream if target_encoder is called with it.\n",
    "    # Its values won't be used for evaluation if test_labels_available is False.\n",
    "    y_test = pd.Series([None] * len(X_test), index=X_test.index, name=user_label_col)\n",
    "    test_labels_available = False\n",
    "    print(f\"  Warning: Target label column '{user_label_col}' not found in 'test_users.csv'. Test set evaluation metrics (accuracy, classification report, confusion matrix) will not be performed.\")\n",
    "\n",
    "print(f\"\\nOriginal feature shape - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Fit on combined train and test data to handle unseen categories\n",
    "    combined_data = pd.concat([X_train[col], X_test[col]], axis=0).astype(str) # Cast to string to handle potential None from y_test if labels not available\n",
    "    le.fit(combined_data)\n",
    "\n",
    "    X_train[col] = le.transform(X_train[col])\n",
    "    X_test[col] = le.transform(X_test[col].astype(str)) # Cast X_test col to string before transforming\n",
    "\n",
    "    label_encoders[col] = le\n",
    "    print(f\"  Encoded '{col}': {len(le.classes_)} unique values\")\n",
    "\n",
    "# Encode target labels (User1, User2, User3)\n",
    "target_encoder = LabelEncoder()\n",
    "y_train_encoded = target_encoder.fit_transform(y_train)\n",
    "\n",
    "if test_labels_available:\n",
    "    y_test_encoded = target_encoder.transform(y_test)\n",
    "    print(f\"\\nTarget classes: {target_encoder.classes_}\")\n",
    "    print(f\"Encoded as: {np.unique(y_train_encoded)}\")\n",
    "else:\n",
    "    # Create a dummy array for y_test_encoded if labels are not available\n",
    "    y_test_encoded = np.full(len(X_test), -1) # Use -1 or another placeholder for unknown labels\n",
    "    print(f\"\\nTarget classes: {target_encoder.classes_} (derived from training data)\")\n",
    "    print(\"  Test set target labels are not available for encoding.\")\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "if len(numerical_cols) > 0:\n",
    "    X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "    X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "    print(f\"\\n✓ Standardized {len(numerical_cols)} numerical features\")\n",
    "\n",
    "print(f\"\\nFinal feature shape - Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(\"\\n✓ Feature encoding completed successfully!\")\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 2: USER CLASSIFICATION (10 POINTS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SECTION 2: USER CLASSIFICATION (10 POINTS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.1 Train Multiple Classification Models\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[2.1] Training Classification Models...\")\n",
    "\n",
    "# Define models to compare\n",
    "models = {\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n--- Training {model_name} ---\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracies\n",
    "    train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "\n",
    "    if test_labels_available:\n",
    "        test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "    else:\n",
    "        test_accuracy = np.nan # Cannot calculate without labels\n",
    "\n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train_encoded, cv=5)\n",
    "    cv_mean = cv_scores.mean()\n",
    "    cv_std = cv_scores.std()\n",
    "\n",
    "    results[model_name] = {\n",
    "        'model': model,\n",
    "        'train_accuracy': train_accuracy,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'cv_mean': cv_mean,\n",
    "        'cv_std': cv_std,\n",
    "        'predictions': y_test_pred\n",
    "    }\n",
    "\n",
    "    print(f\"  Training Accuracy: {train_accuracy:.4f}\")\n",
    "    if test_labels_available:\n",
    "        print(f\"  Test Accuracy: {test_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"  Test Accuracy: N/A (Test labels not available)\")\n",
    "    print(f\"  Cross-Validation: {cv_mean:.4f} (+/- {cv_std:.4f})\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.2 Select Best Model\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[2.2] Model Selection...\")\n",
    "\n",
    "# Compare models\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Model':<25} {'Train Acc':<12} {'Test Acc':<12} {'CV Score':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for model_name, result in results.items():\n",
    "    # Display 'N/A' for test accuracy if not available\n",
    "    test_acc_display = f\"{result['test_accuracy']:.4f}\" if not np.isnan(result['test_accuracy']) else \"N/A\"\n",
    "    print(f\"{model_name:<25} {result['train_accuracy']:<12.4f} \"\n",
    "          f\"{test_acc_display:<12} {result['cv_mean']:<12.4f}\")\n",
    "\n",
    "# Select best model based on test accuracy (if available) or fall back to CV score\n",
    "if test_labels_available:\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k]['test_accuracy'])\n",
    "    best_model = results[best_model_name]['model']\n",
    "    best_test_accuracy = results[best_model_name]['test_accuracy']\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"\\n✓ Best Model: {best_model_name}\")\n",
    "    print(f\"  Test Accuracy: {best_test_accuracy:.4f}\")\n",
    "else:\n",
    "    print(\"-\" * 70)\n",
    "    print(\"\\nSkipping best model selection based on test accuracy as test labels are not available.\")\n",
    "    # Fallback to CV score for best model selection if test labels are not available\n",
    "    best_model_name = max(results.keys(), key=lambda k: results[k]['cv_mean'])\n",
    "    best_model = results[best_model_name]['model']\n",
    "    best_test_accuracy = np.nan # Still N/A for test accuracy\n",
    "    print(f\"✓ Best Model selected based on Cross-Validation score: {best_model_name}\")\n",
    "    print(f\"  (Test Accuracy N/A due to missing labels)\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.3 Detailed Evaluation of Best Model\n",
    "# ----------------------------------------------------------------------------\n",
    "print(f\"\\n[2.3] Detailed Evaluation of {best_model_name}...\")\n",
    "\n",
    "y_test_pred = results[best_model_name]['predictions']\n",
    "\n",
    "if test_labels_available:\n",
    "    # Classification Report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_encoded, y_test_pred,\n",
    "                              target_names=target_encoder.classes_))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test_encoded, y_test_pred)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "else:\n",
    "    print(\"\\n  Skipping detailed evaluation (Classification Report, Confusion Matrix) as test labels are not available.\")\n",
    "    # Create a dummy confusion matrix for plotting if needed\n",
    "    cm = np.zeros((len(target_encoder.classes_), len(target_encoder.classes_))) # Dummy for plotting\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2.4 Visualizations\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n[2.4] Creating Visualizations...\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Model Comparison\n",
    "ax1 = axes[0]\n",
    "model_names = list(results.keys())\n",
    "# Replace NaN with 0 for plotting, or handle display of N/A directly\n",
    "test_accuracies = [results[m]['test_accuracy'] if not np.isnan(results[m]['test_accuracy']) else 0 for m in model_names]\n",
    "cv_means = [results[m]['cv_mean'] for m in model_names]\n",
    "\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, test_accuracies, width, label='Test Accuracy', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, cv_means, width, label='CV Score', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Classification Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(model_names, rotation=15, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        if bars is bars1 and not test_labels_available: # For test accuracy if labels are missing\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height, # Position at height 0 for N/A bar\n",
    "                    'N/A', va='bottom', ha='center', fontsize=9, color='red')\n",
    "        else:\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.3f}',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# Plot 2: Confusion Matrix Heatmap (conditional on test_labels_available)\n",
    "ax2 = axes[1]\n",
    "if test_labels_available:\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_encoder.classes_,\n",
    "                yticklabels=target_encoder.classes_,\n",
    "                ax=ax2, cbar_kws={'label': 'Count'})\n",
    "    ax2.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
    "else:\n",
    "    # If no labels, display a placeholder or empty plot\n",
    "    ax2.text(0.5, 0.5, 'Test Labels Not Available\\nfor Confusion Matrix', # Use 'N/A' as content for clarity\n",
    "             horizontalalignment='center', verticalalignment='center',\n",
    "             transform=ax2.transAxes, fontsize=14, color='red')\n",
    "    ax2.set_axis_off() # Turn off axes for placeholder\n",
    "    ax2.set_title(f'Confusion Matrix - {best_model_name} (N/A)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('classification_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualizations saved as 'classification_results.png'\")\n",
    "\n",
    "# ============================================================================\n",
    "# SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY - FIRST 20 POINTS COMPLETED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n✓ DATA PRE-PROCESSING (10 Points):\")\n",
    "print(f\"  - Loaded {news_articles_clean.shape[0]} news articles\")\n",
    "print(f\"  - Loaded {train_users_clean.shape[0]} training users\")\n",
    "print(f\"  - Loaded {test_users_clean.shape[0]} test users (Note: Target labels for test set were not found)\")\n",
    "print(f\"  - Handled missing values\")\n",
    "print(f\"  - Encoded {len(categorical_cols)} categorical features\")\n",
    "print(f\"  - Standardized {len(numerical_cols)} numerical features\")\n",
    "\n",
    "print(\"\\n✓ USER CLASSIFICATION (10 Points):\")\n",
    "print(f\"  - Trained {len(models)} classification models\")\n",
    "print(f\"  - Best model: {best_model_name}\")\n",
    "if test_labels_available:\n",
    "    print(f\"  - Test accuracy: {best_test_accuracy:.4f} ({best_test_accuracy*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"  - Test accuracy: N/A (Test labels not available for evaluation)\")\n",
    "print(f\"  - User categories: {', '.join(target_encoder.classes_)}\")\n",
    "\n",
    "# Save the context detector (classifier) for later use\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAVING MODEL ARTIFACTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Store important objects for next sections\n",
    "artifacts = {\n",
    "    'classifier': best_model,\n",
    "    'target_encoder': target_encoder,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'numerical_cols': numerical_cols,\n",
    "    'user_label_col': user_label_col,\n",
    "    'news_articles': news_articles_clean,\n",
    "    'X_test': X_test,\n",
    "    'y_test_encoded': y_test_encoded if test_labels_available else 'N/A_NoLabels' # Save y_test_encoded only if meaningful\n",
    "}\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('classifier_artifacts.pkl', 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "\n",
    "print(\"✓ Model artifacts saved to 'classifier_artifacts.pkl'\")\n",
    "print(\"\\nYou can load these artifacts for the remaining sections using:\")\n",
    "print(\"  with open('classifier_artifacts.pkl', 'rb') as f:\")\n",
    "print(\"      artifacts = pickle.load(f)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FIRST 20 POINTS COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
